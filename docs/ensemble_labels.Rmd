---
title: "Ensemble labels"
author: "Lei Song"
date: "`r Sys.Date()`"
output: 
  rmdformats::readthedown:
    highlight: pygments
    toc_depth: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

## Introduction
In order to make full use of other existing land cover (LC) products, and save the energy to gather new labels. We decided to ensemble these chosen LC products to make new labels for training. We chose these products based upon their relatively high spatial resolution and recent produce time.
These products include:

- Finer Resolution Observation and Monitoring of Global Land Cover (FROM-GLC10) 2017 (10 m)
- S2 prototype land cover map of Africa 2016 (20 m)
- Global Food Security-support Analysis Data (GFSAD) cropland extent of Africa 2015 (30 m)
- Copernicus global land cover map 2018 (100 m) (We chose it because of the most recent year.)

This project provides a practical framework to rapidly generate regional high resolution land cover map on demand. Due to the spatial limitation of Planet NICFI basemap, We only focus on sub-Saharan Africa and take Tanzania as a case study.

## Week near point-level LC labels
First, we redefined LC types to ensure that different products match each other. 
Then, we ensemble all LC products to generate LC type labels, and resample to the highest resolution.

### Read related vectors
```{r read}
library(dplyr)
library(terra)
library(sf)
tiles <- vect('data/geoms/tiles_nicfi.geojson')
```

### Mosaic and clip the products
```{r mosaic}
ext_dir <- '/Volumes/elephant/landcovers'

# ESACCI
esacci <- rast(file.path(ext_dir, 
                         'ESACCI-LC-L4-LC10-Map-20m-P1Y-2016-v1',
                         'ESACCI-LC-L4-LC10-Map-20m-P1Y-2016-v1.0.tif')) %>% 
    crop(tiles) %>% mask(tiles)

# FROM_GLC
fnames <- list.files(file.path(ext_dir, 
                               'FROM_GLC_2017'),
                     full.names = T)
fromglc <- do.call(merge, lapply(fnames, function(fname){
    rast(fname)
})) %>% crop(tiles) %>% mask(tiles)

# GFSAD30AFCE
fnames <- list.files(file.path(ext_dir, 
                               'GFSAD30AFCE_2015'),
                     full.names = T,
                     pattern = 'tif$')
gfsad <- do.call(merge, lapply(fnames, function(fname){
    rast(fname)
})) %>% crop(tiles) %>% mask(tiles)

# ESAGLC
fnames <- list.files(file.path(ext_dir, 
                               'ESA_GLC_2018'),
                     full.names = T)
esaglc <- do.call(merge, lapply(fnames, function(fname){
    rast(fname)
})) %>% crop(tiles) %>% mask(tiles)
```

### Redefine land cover types
**UN-FAOâ€™s Land Cover Classification System (LCCS)**
```
(1) Cultivated and Managed Terrestrial Areas (cropland), 
(2) Natural and Semi-Natural Terrestrial Vegetation, 
(3) Cultivated Aquatic or Regularly Flooded Areas, 
(4) Natural and Semi-Natural Aquatic or Regularly Flooded Vegetation, 
(5) Artificial Surfaces and Associated Areas, 
(6) Bare Areas, 
(7) Artificial Waterbodies, Snow and Ice, and 
(8) Natural Waterbodies, Snow and Ice.
```

**ESACCI**
```
0	No data
1   Tree cover areas
2	Shrubs cover areas
3	Grassland
4	Cropland
5	Vegetation aquatic or regularly flooded
6	Lichens Mosses / Sparse vegetation
7	Bare areas
8	Built up areas
9	Snow and/or Ice
10	Open Water
```

**ESAGLC**
```
0 No input data
111 Closed forest, evergreen needle leaf
113 Closed forest, deciduous needle leaf
112 Closed forest, evergreen, broad leaf
114 Closed forest, deciduous broad leaf
115 Closed forest, mixed
116 Closed forest, unknown
121 Open forest, evergreen needle leaf
123 Open forest, deciduous needle leaf
122 Open forest, evergreen broad leaf
124 Open forest, deciduous broad leaf
125 Open forest, mixed
126 Open forest, unknown
20 Shrubs
30 Herbaceous vegetation
90 Herbaceous wetland
100 Moss and lichen
60 Bare / sparse vegetation
40 Cultivated and managed vegetation / agriculture (cropland)
50 Urban / built up
70 Snow and ice
80 Permanent water bodies
200 Open sea
```

**FROM-GLC**
```
Name	             Code
Cropland	         1
Forest	           2
Grassland	         3
Shrubland	         4
Wetland	           5
Water	             6
Tundra	           7
Impervious surface 8
Bareland	         9
Snow/Ice	         10
```

**GFSAD**
```
Cropland Extent Class Descriptions

Class Label	         Name	           Description
0	                 Water	           Water bodies/no-data
1	                 Non-Cropland	   Non-Cropland areas
2	                 Cropland	       Cropland areas
```

#### Generate convert tables
```{r refine}
# LC type used
lc_types <- data.frame(id = seq(1, 10),
                       name = c('Cropland', 'Forest', 'Grassland', 
                                'Shrubland', 'Wetland', 'Water', 
                                'Tundra', 'Urban/Built up',
                                'Bareland', 'Snow/Ice'))

# types of LC products
esacci_table <- data.frame(id = c(seq(1, 10)),
                           name = c('Tree cover areas', 
                                    'Shrub cover areas', 
                                    'Grassland', 'Cropland', 
                                    'Vegetation aquatic or regularly flooded',
                                    'Lichens Mosses / Sparse vegetation',
                                    'Bare areas', 'Built up areas', 
                                    'Snow and/or Ice', 'Open Water'),
                           convert = c(2, 4, 3, 1, 5, 7, 9, 8, 10, 6))

names <- c('Closed forest, evergreen needle leaf',
           'Closed forest, evergreen, broad leaf',
           'Closed forest, deciduous needle leaf',
           'Closed forest, deciduous broad leaf',
           'Closed forest, mixed',
           'Closed forest, unknown',
           'Open forest, evergreen needle leaf',
           'Open forest, evergreen broad leaf',
           'Open forest, deciduous needle leaf',
           'Open forest, deciduous broad leaf',
           'Open forest, mixed',
           'Open forest, unknown',
           'Shrubs', 'Herbaceous vegetation',
           'Herbaceous wetland', 'Moss and lichen',
           'Bare / sparse vegetation',
           'Cultivated and managed vegetation / agriculture (cropland)',
           'Urban / built up',
           'Snow and ice',
           'Permanent water bodies',
           'Open sea')
esaglc_table <- data.frame(id = c(seq(111, 116), 
                                  seq(121, 126), 
                                  20, 30, 90, 100, 60, 
                                  40, 50, 70, 80, 200),
                           name = names,
                           convert = c(rep(2, 12), 4, 
                                       3, 5, 7, 9, 1,
                                       8, 10, 6, 6))

fromglc_table <- data.frame(id = seq(1, 10),
                            name = c('Cropland', 'Forest', 'Grassland',
                                     'Shrubland', 'Wetland', 'Water',
                                     'Tundra', 'Impervious surface',
                                     'Bareland', 'Snow/Ice'),
                            convert = seq(1, 10))

gfsad_table <- data.frame(id = seq(0, 2),
                          name = c('Water',
                                   'Non-Cropland',
                                   'Cropland'),
                          convert = c(6, NA, 1))
```

#### Convert LC maps
```{r convert}
# Path
dst_path <- 'data/landcovers'
if (!dir.exists(dst_path)) dir.create(dst_path)

# ESACCI reclassification
esacci_rclmat <- data.frame(from = esacci_table$id - 1,
                            to = esacci_table$id, 
                            becomes = esacci_table$convert) %>% 
  as.matrix()
esacci_new <- classify(esacci, esacci_rclmat, 
                       right = FALSE, 
                       othersNA = TRUE,
                       filename = file.path(dst_path, 
                                            'esacci_rcl.tif'),
                       wopt = list(datatype = 'INT1U',
                                   gdal=c("COMPRESS=LZW")))

# ESA-GLC reclassification
esaglc_rclmat <- data.frame(from = esaglc_table$id - 1,
                            to = esaglc_table$id, 
                            becomes = esaglc_table$convert) %>% 
  as.matrix()
esaglc_new <- classify(esaglc, esaglc_rclmat, 
                       right = FALSE, 
                       othersNA = TRUE,
                       filename = file.path(dst_path, 
                                            'esaglc_rcl.tif'),
                       wopt = list(datatype = 'INT1U',
                                   gdal=c("COMPRESS=LZW")))

# FROM-GLC reclassification
fromglc_rclmat <- data.frame(from = fromglc_table$id - 1,
                             to = fromglc_table$id, 
                             becomes = fromglc_table$convert) %>% 
  as.matrix()
fromglc_new <- classify(fromglc, fromglc_rclmat, 
                        right = FALSE, 
                        othersNA = TRUE,
                        filename = file.path(dst_path, 
                                             'fromglc_rcl.tif'),
                        wopt = list(datatype = 'INT1U',
                                    gdal=c("COMPRESS=LZW")))

# GFSAD reclassification
gfsad_rclmat <- data.frame(from = gfsad_table$id - 1,
                           to = gfsad_table$id, 
                           becomes = gfsad_table$convert) %>% 
  as.matrix()
gfsad_new <- classify(gfsad, gfsad_rclmat, 
                      right = FALSE, 
                      othersNA = TRUE,
                      filename = file.path(dst_path, 'gfsad_rcl.tif'),
                      wopt = list(datatype = 'INT1U',
                                  gdal=c("COMPRESS=LZW")))
```

### Make labels
The pixel non-0 value in the image matches with the values in `lc_types`.

```{r make_labels}
# Path
dst_path <- 'data/intermid/lc_labels'
if (!dir.exists(dst_path)) dir.create(dst_path)

# Get the existing types
# Because not all types exist in the current study area
ids <- unique(c(unique(esacci_new), 
                unique(esaglc_new), 
                unique(fromglc_new), 
                1)) # For GFSAD
lc_types <- lc_types %>% filter(id %in% ids)
  
lapply(1:nrow(lc_types), function(n){
  lc <- lc_types %>% slice(n)
  message(lc$name)
  if (lc$id %in% c(1, 6)){
    message('Use all four products for cropland or water.')
    lc_lb_esacci <- esacci_new == lc$id
    lc_lb_esaglc <- resample(esaglc_new == lc$id, 
                             lc_lb_esacci, 
                             method = 'near')
    lc_lb_fromglc <- resample(fromglc_new == lc$id,
                              lc_lb_esacci, 
                              method = 'near')
    lc_lb_gfsad <- resample(gfsad_new == lc$id, 
                            lc_lb_esacci, 
                            method = 'near')
    lc_lb_emb <- (lc_lb_esacci + 
                    lc_lb_esaglc + 
                    lc_lb_fromglc + 
                    lc_lb_gfsad) == 4
    rm(lc_lb_esacci, lc_lb_esaglc, 
       lc_lb_fromglc, lc_lb_gfsad); gc()
  } else {
    message('Not use GFSAD for other types.')
    lc_lb_esacci <- esacci_new == lc$id
    lc_lb_esaglc <- resample(esaglc_new == lc$id, 
                             lc_lb_esacci,
                             method = 'near')
    lc_lb_fromglc <- resample(fromglc_new == lc$id, 
                              lc_lb_esacci, 
                              method = 'near')
    lc_lb_emb <- (lc_lb_esacci + 
                    lc_lb_esaglc + 
                    lc_lb_fromglc) == 3
    rm(lc_lb_esacci, lc_lb_esaglc, 
       lc_lb_fromglc); gc()
  }
  
  # Save out
  lc_lb_emb[lc_lb_emb == 1] <- n
  fn <- file.path(dst_path, 
                  paste0(gsub('/| ', '_', 
                              lc$name), 
                         '.tif'))
  writeRaster(lc_lb_emb, fn, 
              wopt = list(datatype = 'INT1U',
                          gdal=c("COMPRESS=LZW")))
  rm(lc_lb_emb);gc()
})
```

### Labels summary

```{r summary}
labels_sum <- do.call(rbind, 
                      lapply(1:nrow(lc_types), 
                             function(n){
  lc <- lc_types %>% slice(n)
  message(lc$name)
  fn <- file.path(dst_path, 
                  paste0(gsub('/| ', '_', lc$name), 
                         '.tif'))
  lb_sum <- rast(fn) %>% freq()
  label_count <- 0
  label_frac <- 0
  if (nrow(lb_sum) > 1){
    label_count <- lb_sum[2, 3]
  label_frac <- lb_sum[2, 3] / 
    (lb_sum[1, 3] + lb_sum[2, 3])
  }
  data.frame(name = lc$name, 
             count = label_count,
             frac = label_frac)
}))

# Save out
dst_path <- 'data/intermid'
if (!dir.exists(dst_path)) dir.create(dst_path)
write.csv(labels_sum, 
          file.path(dst_path,
                    'labels_sum.csv'),
          row.names = F)
```

```{r show, eval=T, echo=F, message=F, warning=F}
library(here)
library(kableExtra)
dst_path <- 'data/intermid'
labels_sum <- read.csv(here(file.path(dst_path,
                                      'labels_sum.csv')),
                       stringsAsFactors = F)
labels_sum %>%
  kbl(caption = "Ensemble label summary table") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```

For Tanzania case, there is no Tundra and Snow/Ice type because Tanzania is a tropical country.

### Independent validation labels
Based on the extent of all labels generated above, we selected 4000 random points to manually check the LC type by visual interpretation. In order to cover all LC types, we use strata sampling for each types. The result validation labels will be used for

- Label quality evaluation, and
- Model result evaluation.

We also selected 4000 random points outside of the label extent to evaluate the result outside.

```{r valid}
dst_path <- 'data/intermid/lc_labels'
labels <- do.call(c, 
                  lapply(1:nrow(lc_types), 
                         function(n){
  lc <- lc_types %>% slice(n)
  message(lc$name)
  fn <- file.path(dst_path, 
                  paste0(gsub('/| ', '_', lc$name), 
                         '.tif'))
  rast(fn)
}))

########### Get samples inside ############
size <- 500
labels_sum <- labels_sum %>% filter(count > 0)
pts_inside <- do.call(rbind, 
                      lapply(1:nrow(labels_sum), 
                      function(n){
  lc <- labels_sum %>% slice(n)
  message(lc$name)
  fn <- file.path(dst_path, 
                  paste0(gsub('/| ', '_', lc$name), 
                         '.tif'))
  each <- rast(fn)
  set.seed(123)
  cells <- spatSample(each, 100000, 
                      "random", cells = TRUE)
  v <- each[cells]
  xy <- xyFromCell(each, cells)
  pts <- data.frame(xy, v) %>% 
    setNames(c('x', 'y', 'label_ensemble')) %>% 
    filter(label_ensemble != 0)
  if (nrow(pts) < 500){
    cells <- spatSample(each, 600000 * 3, 
                      "random", cells = TRUE)
    v <- each[cells]
    xy <- xyFromCell(each, cells)
    pts <- data.frame(xy, v) %>% 
      setNames(c('x', 'y', 'label_ensemble')) %>% 
      filter(label_ensemble != 0)
    
    if (nrow(pts) < 500){
    cells <- spatSample(each, 600000 * 8, 
                      "random", cells = TRUE)
    v <- each[cells]
    xy <- xyFromCell(each, cells)
    pts <- data.frame(xy, v) %>% 
      setNames(c('x', 'y', 'label_ensemble')) %>% 
      filter(label_ensemble != 0)
  }
  }
  set.seed(456)
  pts <- pts %>% 
    sample_n(size) %>% 
    st_as_sf(coords = c('x', 'y'),
             crs = 4326) %>% 
    mutate(type = NA) %>% 
    dplyr::select(type, label_ensemble)
  rm(each, cells, v, xy);gc();pts
}))

########## Get samples outside ############
# 1 for labeling region, 
# and 2 for other region within the study area
labels_ext <- sum(labels) >= 1
labels_ext <- mask(labels_ext, tiles)
labels_ext[labels_ext == 0] <- 2

# Generate points outside
size <- 4000
set.seed(123)
# Because we use terra 0.9-11, in which spatSample can't ignore NAs.
# So we complex it a bit.
# Using terra >= 1.0-7, you could ignore NAs when sampling.
# In order to reproduce the code, you could set ma.rm = F in the newer version of the function.
cells <- spatSample(labels_ext, 400000, 
                    "random", cells = TRUE)
v <- labels_ext[cells]
xy <- xyFromCell(labels_ext, cells)
set.seed(456)
pts_outside <- data.frame(xy, v) %>% 
  filter(sum == 2) %>% 
  dplyr::select(-sum) %>% 
  sample_n(size) %>% 
  st_as_sf(coords = c('x', 'y'),
           crs = 4326) %>% 
  mutate(type = NA, label_ensemble = NA) %>% 
  dplyr::select(type, label_ensemble)
rm(cells, v, xy);gc()

pts <- rbind(pts_inside, pts_outside) %>% 
  mutate(id = 1:nrow(.))

# Save out
dst_path <- 'data/intermid'
fn <- file.path(dst_path, 'labels_extent.tif')
writeRaster(labels_ext, fn, 
              wopt = list(datatype = 'INT1U',
                          gdal=c("COMPRESS=LZW")))
st_write(pts, file.path(dst_path, 'validation_ipd_full.geojson'))
pts <- pts %>% dplyr::select(-label_ensemble)
st_write(pts, file.path(dst_path, 'validation_ipd_labelling.geojson'))
```

The rest work out of this document is to manually check the LC type for these random points using human interpretation. The user can drop the points that are not clear to tell.

```{r pts, eval=T, echo=F, warning=F, message=F}
library(sf)
library(here)
library(ggplot2)
pts <- st_read(here(file.path(dst_path, 
                              'validation_ipd_full.geojson')), 
               quiet = T)
ggplot(pts) + geom_sf() + 
  theme_bw()
```

### Generate weak labels

#### Generate the overall labels 
```{r}
val_pts <- st_read('data/intermid/validation_ipd_full.geojson',
                   quiet = T) %>% st_coordinates()

# Because of the maximum number for matrix in R is 2^31 - 1,
# so we have to split the whole raster into blocks to process.
blocks <- aggregate(labels, fact = floor(sqrt(ncell(labels)/3.5)))
values(blocks) <- 1:ncell(blocks)
blocks <- as.polygons(blocks)
labels_exd_val <- do.call(merge, lapply(1:nrow(blocks), function(n){
  block <- blocks[n, ]
  labels_blk <- crop(labels, block)
  val_cells <- na.omit(cellFromXY(labels_blk, val_pts))
  labels_blk[val_cells] <- NA
  rm(block, val_cells);gc();labels_blk
}))

writeRaster(labels, 'data/intermid/lc_labels_exd_val.tif',
            wopt = list(datatype = 'INT1U',
                        gdal=c("COMPRESS=LZW")))
```

#### Select out sub-grids

But in order to get more labels for minor type, we:

- For bareland, wetland, and urban, we sample 95% as train;
- For shrubland and grassland, we sample 20% as train;
- For cropland we sample 10% as train;
- For water and forest, we sample 5% as train.

```{r}
library(tidyr)
library(parallel)
# Define the width of chips to cut
# In this case, 256 *256 chip.
width_chips <- 16
lc_labels <- rast('data/intermid/lc_labels_exd_val.tif')
tiles <- st_read('data/geoms/tiles_nicfi.geojson',
                 quiet = T) %>% dplyr::select(tile)
tiles <- do.call(rbind, mclapply(1:nrow(tiles), function(n){
  tile <- tiles %>% slice(n)
  tiles_grids <- st_make_grid(tile, n = c(width_chips, width_chips)) %>% 
    st_sf() %>% arrange() %>% 
    mutate(tile = tile$tile,
                       index = c(1:(width_chips^2)))
}, mc.cores = 12))
st_write(tiles, 'data/intermid/tiles_grids_256.geojson')
tiles <- tiles %>% vect()

tiles_labels <- mclapply(1:nrow(tiles), function(n){
  labels_each <- crop(lc_labels, tiles[n, ])
  lb <- freq(labels_each) %>% data.frame() %>% 
    filter(value != 0) %>%
    mutate(count = count / (dim(labels_each)[1] * dim(labels_each)[2])) %>%
    left_join(., lc_types, by = c('value' = 'id')) %>%
    dplyr::select(-c(value, layer)) %>%
    pivot_wider(names_from = name, values_from = count) %>%
    mutate(tile = tiles[n, ]$tile,
           index = tiles[n, ]$index)
  if (nrow(lb) > 0) lb
}, mc.cores = 12) %>% bind_rows()
save(tiles_labels, file = 'data/intermid/tiles_labels_256.rda')

labels_sum <- labels_sum %>% filter(count > 0)
tiles_grids_selected <- do.call(rbind, 
                                lapply(labels_sum$name, 
                                       function(nm){
    message(nm)
    if (nm %in% c('Forest', 'Grassland', 'Cropland', 'Shrubland')){
        set.seed(123)
        tile_select <- tiles_labels %>% 
            dplyr::select(tile, index, nm) %>% 
            # arrange_at(nm, funs(desc)) %>% 
            filter(!is.na(!!rlang::sym(nm))) %>% 
            filter((!!rlang::sym(nm)) >= 0.7) %>% 
            sample_n(min(1000, nrow(.)))
    } else if (nm == 'Water'){
        set.seed(566)
        tile_select <- tiles_labels %>% 
            dplyr::select(tile, index, nm) %>% 
            # arrange_at(nm, funs(desc)) %>% 
            filter(!is.na(!!rlang::sym(nm))) %>%
            filter((!!rlang::sym(nm)) <= 0.8) %>%
            filter((!!rlang::sym(nm)) >= 0.4) %>% 
            sample_n(500)
    } else {
        # Bare land, wetland, and urban are classes that are hard to tell,
        # and the ensemble labels are less,
        # so we keep as many samples as possible.
        # but also if there are too few labels within a grid,
        # we assume the labels are not reliable anymore.
        # So we use a threshold 0.1.
        tile_select <- tiles_labels %>% 
            dplyr::select(tile, index, all_of(nm)) %>%
            filter(!is.na(!!rlang::sym(nm))) %>%
            filter((!!rlang::sym(nm)) > 0.1)
    }
    data.frame(name = nm, 
               tile = tile_select$tile, 
               index = tile_select$index)
}))
```

#### Split training, validation, and test

```{r split}
set.seed(1000)
tiles_grids_train <- tiles_grids_selected %>% 
  group_by(name) %>% sample_frac(0.6) %>% 
  ungroup() %>% dplyr::select(-name) %>% 
  unique() %>% mutate(usage = 'train') %>%
  dplyr::select(tile, index, usage)
set.seed(1200)
tiles_grids_valid <- tiles_grids_selected %>% 
  anti_join(tiles_grids_train, 
            by = c('tile', 'index')) %>% 
  group_by(name) %>% sample_frac(0.6) %>% 
  ungroup() %>% dplyr::select(-name) %>% 
  unique() %>% mutate(usage = 'validate') %>%  
  dplyr::select(tile, index, usage)
tiles_grids_test <- tiles_grids_selected %>%
  dplyr::select(-name) %>% unique() %>% 
  anti_join(tiles_grids_train) %>% 
  anti_join(tiles_grids_valid) %>% 
  mutate(usage = 'test') %>% 
  dplyr::select(tile, index, usage)
catalog_train_val_test <- rbind(tiles_grids_train, 
                               tiles_grids_valid, 
                               tiles_grids_test)
write.csv(catalog_train_val_test, 
          'data/intermid/catalog_train_val_test.csv',
          row.names = F)
```

#### Generate labels images
In order to save the resources for deep learning, we re-defined the class index to be continuous. So:

```
id          name
1       Cropland
2         Forest
3      Grassland
4      Shrubland
5        Wetland
6          Water
7 Urban/Built up (8)
8       Bareland (9)
```

```{r labels_img}
library(glue)
tiles <- st_read('data/intermid/tiles_grids.geojson',
                 quiet = T)
lc_labels <- rast('data/intermid/lc_labels_exd_val.tif')

plt_path <- '/Volumes/elephant/plt_nicfi'
plt_nms <- list.files(plt_path, full.names = T)
labels_path <- '/Volumes/elephant/labels'

mclapply(unique(catalog_train_val_test$tile), 
         function(tile_nm){
  tiles_each <- catalog_train_val_test %>% 
    filter(tile == tile_nm)
  lc_labels_each <- crop(lc_labels, tiles %>% 
                           filter(tile == tile_nm) %>% 
                           st_union() %>% 
                           st_buffer(0.01) %>% 
                           st_sf() %>% vect())
  nm <- grep(tile_nm, plt_nms, value = TRUE)[1]
  temp <- rast(nm)[[1]] %>% 
    aggregate(fact = 4096/width_chips)
  vals <- matrix(1:(width_chips^2), 
                 nrow = width_chips, 
                 ncol = width_chips) %>% t()
  vals <- vals[nrow(vals):1, ]
  values(temp) <- vals
  lapply(1:nrow(tiles_each), function(n){
    tile_each <- tiles_each %>% slice(n)
    temp_each <- temp
    index <- tile_each$index
    temp_each[temp_each != index] <- NA
    temp_each <- terra::trim(temp_each) %>% 
      disaggregate(fact = 4096/width_chips)
    label_each <- resample(lc_labels_each, temp_each, method = 'near')
    label_each[label_each == 8] <- 7
    label_each[label_each == 9] <- 8
    writeRaster(label_each, 
                file.path(labels_path, 
                          glue('labels_{tile_nm}_{index}.tif')),
                wopt = list(datatype = 'INT1U',
                        gdal=c("COMPRESS=LZW")))
    rm(tile_each, temp_each, label_each, index);gc()
  })
  rm(tiles_each, lc_labels_each, nm, temp, vals);gc()
}, mc.cores = 12)
```

### Sampling the label points [DEPRECATED]
*Purely point-based deep learning is not very ideal for such a big area, since it will waste
a lot of hardware resources, or waste time on prediction. But it might be an idea for a small region or an idea for traditional machine learning (e.g. random forest). Here we keep the details here.*

Since these labels are ensemble and distribute across the whole study area, we assume that they are representative enough. To reduce the training time and the potential noises within the labels due to the spatial resolution mismatch, we sample 20% from the label ensemble to calibrate the model, and 10% to evaluate.
we designed to sample from the ensemble labels:

- 20% as training pool, separately.

But in order to get more labels for minor type, we:

- For bareland, wetland, and urban, we sample 95% as train;
- For shrubland and grassland, we sample 20% as train;
- For cropland we sample 10% as train;
- For water and forest, we sample 5% as train.

And we sample 5% * smallest ensemble label size (Bareland) as validation.

```{r sampling}
library(glue)
library(rgrass7)

# Get the sample size for each type
labels_sum <- labels_sum %>% filter(count > 0)
sample_lb_size <- do.call(rbind, 
                  lapply(1:nrow(labels_sum), 
                  function(n){
  lc <- labels_sum %>% slice(n)
  message(lc$name)
  # Because forest and water have very clear characteristics
  # comparing to others, and the amount of ensemble labels are large,
  # so we choose less samples for these two classes.
  if (lc$name %in% c('Forest', 'Water')){
    size <- floor(lc$count * 0.05)
  } else if (lc$name == 'Cropland'){
    size <- floor(lc$count * 0.1)
  } else if (lc$name %in% c('Grassland', 'Shrubland')){
    size <- floor(lc$count * 0.2)
  } else{
    # Bare land, wetland, and urban are classes that are hard to tell,
    # and the ensemble labels are less,
    # so we keep as many samples as possible.
    size <- floor(lc$count * 0.95)
  }
  data.frame(name = lc$name, sample_size = size)
}))
sample_lb_size <- merge(sample_lb_size, lc_types, by = 'name') %>% 
  arrange(id)

fn <- 'data/intermid/lc_labels_exd_val.tif'
gisBase <- "/Applications/GRASS-7.9.app/Contents/Resources"
initGRASS(gisBase = gisBase,
          home = tempdir(),
          gisDbase = tempdir(),  
          mapset = 'PERMANENT', 
          location = 'sampling', 
          override = TRUE)
execGRASS("g.proj", flags = "c", 
          proj4="+proj=longlat +datum=WGS84 +no_defs")
execGRASS('r.in.gdal', flags = c("o", "overwrite"),
          input = here(fn),
          band = 1,
          output = "label")
execGRASS("g.region", raster = "label")
execGRASS("r.null", parameters = list(map = 'label', 
                                      setnull = '0'))
execGRASS("r.sample.category", flags = c("overwrite"), 
          parameters = list(input = 'label', 
                            output = 'pts',
                            npoints = sample_lb_size$sample_size,
                            random_seed = 345))
## Read out
use_sf()
pts <- readVECT("pts") %>% dplyr::select(-cat)
st_write(pts, 'data/intermid/lc_labels.geojson')

## Sign the labels into tiles
tiles <- st_read('data/geoms/tiles_nicfi.geojson',
                 quiet = T) %>% dplyr::select(tile)
pts_its <- st_intersects(tiles, pts)
dst_path <- '/Volumes/elephant/labels'
for (n in 1:length(pts_its)){
  print(n)
  nm <- tiles %>% slice(n) %>% pull(tile)
  pts_tile <- pts %>% slice(pts_its[[n]])
  if (nrow(pts_tile) > 0){
    st_write(pts_tile, glue('{dst_path}/labels_{nm}.geojson'),
             quiet = T)
  }
  rm(nm, pts_tile);gc()
}

pts_assigned <- lapply(1:nrow(tiles), function(n){
  tile <- tiles %>% slice(n)
  pts_tile <- st_intersection(pts, tile)
  rm(tile);gc();pts_tile
})
```

## Other avaliable labels from ground observation
We collected a few public available LC/cropland labels. The objective of these labels are:

1. Evaluate the performance of just using ensemble labels by comparing the results with/without these extra labels.
2. As an independent evaluation dataset to test the method performance.

The labels include:

- Radiant Earth MLHub crop type labels (`ref_crops.geojson`) (2018).
- Manually collected labels (`user_maps_tz.geojson`) (2018).
- Tanzania TAMASA (2017)
- TANSIS (2017)
- more [NEED TO UPDATE]

### Radiant earth MLHub
The files were parsed based on [MLHub API tutorials](https://github.com/radiantearth/mlhub-tutorials). We only used crop type labels in our study area Tanzania. The labels are ground collection with boundary drawn using imagery. The labels are concentrated in the Northern area, which is a large agricultural region in Tanzania.

```{r mlhub, eval=T, echo=F, warning=F, message=F}
library(sf)
library(here)
library(ggplot2)
bry <- st_read(here('data/geoms/tanzania.geojson'), quiet = T)
ref_tz_crops <- st_read(here('data/references/ref_crops.geojson'), quiet = T)
ggplot(bry) + geom_sf() + 
  geom_sf(data = ref_tz_crops, aes(color = crop)) +
  scale_color_brewer(palette = "Dark2") + 
  theme_bw()
```

### Collected labels
These labels are collected by us using PlanetScope image in 2018 and other base maps. The labels are also concentrated in north.

```{r clt, eval=T, echo=F, warning=F, message=F}
user_maps <- st_read(here('data/references/user_maps_tz.geojson'), quiet = T)
ggplot(bry) + geom_sf() + 
  geom_sf(data = user_maps, color = "#FC4E07") +
  theme_bw()
```

### TAMASA

```{r}
tamasa_tz <- read.csv("data/TAMASA/TAMASA_TZ_APS_2017_CC_MaizeYield.csv",
                       stringsAsFactors = F) %>% 
  filter(!is.na(Longitude) & !is.na(Latitude)) %>% 
  st_as_sf(coords = c('Longitude', 'Latitude'), crs = 4326)
st_write(tamasa_tz, "data/TAMASA/tamasa_tz_maize_2017.geojson")

tamasa_tz_mt <- read.csv("data/TAMASA/TZ_TAMASA_APS_2017_Maize_Yield_MetaData_v2.csv",
                       stringsAsFactors = F) %>% 
  filter(!is.na(Longitude) & !is.na(Latitude)) %>% 
  st_as_sf(coords = c('Longitude', 'Latitude'), crs = 4326)
st_write(tamasa_tz_mt, "data/TAMASA/tamasa_tz_maize_2017_metadata.geojson")
```

