---
title: "Run deep learning on AWS instance"
author: "Lei Song"
date: "`r Sys.Date()`"
output: 
  rmdformats::readthedown:
    highlight: pygments
    toc_depth: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

## Launch instance
The information of instance that we used:

- AMI ID: `ami-0643df3b347740189`, which is our customized deep learning AWS instance.
- Instance type: `g3.8xlarge`.
- Security group: `labeller-security`.

Before start, install `jq`.
Then use the scripts in `pytorch_planet/aws_tools/create_spot_instance.sh` using the template:
```
cd /path/to/pytorch_planet/folder
chmod 777 ./aws_tools/create_spot_instance.sh
./aws_tools/create_spot_instance.sh <ami_id> <instance_type> <security_group_id> <new_instance_name> <spot_type> <valid_until> <key_name>
```
For example:
```
cd /path/to/pytorch_planet/folder
chmod 777 ./aws_tools/create_spot_instance.sh
./aws_tools/create_spot_instance.sh ami-0643df3b347740189 g3.16xlarge sg-0a8bbc91697d6a76b lc_dl_tz persistent 2021-01-22T23:00:00 lsong-keypair
```

## Parameters setting
After successfully launched the instance, then it is ready to get into the instance to work.

The most essential work are arguably to clone project and set jupyter notebook:

- STEP 1: Set up GitHub token (because the repo is private). More details could be found in this [tutorial](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent).

  ```
  ssh-keygen -t ed25519 -C "your_email@example.com"
  eval "$(ssh-agent -s)"
  ssh-add ~/.ssh/id_ed25519
  vim ~/.ssh/id_ed25519.pub
  ```
  Copy out the ssh key, and type `:q` to exit, and then go to GitHub page to add into the records.
    
- STEP 2: Clone the repo into instance:
  
  ```
  git clone git@github.com:agroimpacts/pytorch_planet.git
  ```
  
  If necessary, use `git checkout` to switch branch and use `git pull` to grab the updates.
  
- STEP 3: Set up jupyter notebook

  ```
  jupyter notebook password
  ```
  to set a log in password for jupyter notebook, then
  ```
  jupyter notebook
  ```
  replace the private IP with the public IP to open it in browser. If you can log in without issues, then it is ready to go.

## Experiemnts

### Experiment 1

```
Model: Deeplab3+
train_batch = 32
val_batch = 16
transformation = ['vflip', 'hflip', 'rotate', 'resize']
rotate_degree = [-90, 90]
epoch = 30
lr_init = 0.0005
lr_decay = 0.1
lr_decay_step = 1
momentum = 0.99
criterion = BalancedTverskyFocalLoss(ignore_index=0)
optimizer = "adam"
```

**Result**: terminate early. The model performance stuck quickly. Then it got stuck here.

```
train loss: 0.6423281792689253
train acc: 0.7882347084857799
validation loss: 0.872987336890642
validation acc: 0.8824300759060438
time: 409
[14/100]
train loss: 0.6659585610032082
train acc: 0.7867565039131377
validation loss: 0.8747954650153947
validation acc: 0.8814900846675385
time: 391
```

Seems like BalancedTverskyFocalLoss and adam is a good combination of compiler parameters. The problems left is which model and the learning rate. The experiments shown that the complexity of the model is not enough.

### Experiments

```
Model: Unet

train loss: 0.6717923217349582
train acc: 0.7490688176066788
validation loss: 0.8887722446301649
validation acc: 0.8503072788549024
```

```
Model: Deeper Unet

train loss: 0.6798290364720203
train acc: 0.7305447139121868
validation loss: 0.8891407523390858
validation acc: 0.8469047265690427
time: 245
```

```
Model: VGG 
```

```
Model: ResNet 
```

```
Model: DenseNet 
```

```
Model: SegNet 
```