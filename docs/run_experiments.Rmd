---
title: "Introduction of using AWS instance to run experiments"
author: "Lei Song"
date: "`r Sys.Date()`"
output: 
  rmdformats::readthedown:
    highlight: pygments
    toc_depth: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

## GPU Resources

It is very straightforward to use ASU Sol cluster to run the experiments. I every time start a GPU RStudio Server to run the scripts. It is convenient to check something interactively and quickly. More importantly, I have no idea why the conda environment cannot work in other nodes. At least, I am happy with this way for now. The setting of RStudio Server is:

- CPU cores: 35
- Rstudio Wall Time: 2 days is way more than enough.
- R version: 4.2.1
- GPU resources: gpu:a100:4
- CPU RAM: --mem=400G

## Conda environment

`pytorch_spatial` is the conda environment to run all scripts. The users can get into the environment by:

```
module load mamba/latest
source activate pytorch_spatial
```

If this is the first time ever for this work, clone the repo into instance:

```
git clone git@github.com:LLeiSong/hrlcm.git
```
  
If necessary, use `git checkout` to switch branch and use `git pull` to grab the updates.
  
## Run experiments
### Tensorboard

If download log file to local machine, then it is easy to check the training loss curves.

`tensorboard --logdir='./tensorboard_dirs' --port=16007`

Do the following steps to use the tensorboard on a remote server (reference: https://blog.yyliu.net/remote-tensorboard/):

1. You need to start SSH with transfer the remote serverâ€™s port to your local PC:

    (on your local PC) `ssh -L 16007:127.0.0.1:16007 username@server_ip`

2. Then you may start the tensorboard on the remote server with the specific port we want to transfer:

    (on the remote server) `tensorboard --logdir='./tensorboard_dirs' --port=16007`
    
### Fit the model

Load conda environment:

```
module load mamba/latest
source activate pytorch_spatial
```
Run script to fit the model:

```
python hrlcm/fit_compose_lr.py --exp_name unet_128_20bs_sbaug_startup --num_workers 30 --gpu_devices '0,1,2,3'
python hrlcm/fit_compose_lr.py --exp_name unet_128_20bs_sbaug_tune --num_workers 30 --gpu_devices '0,1,2,3' --resume '/scratch/lsong36/tanzania/results/unet_128_20bs_sbaug_startup/checkpoints/final.pth'
```

### Predict of labels of years

One GPU and use batch size 32 is enough. This step would be very fast as long as CPU RAM can load the dataset.

2018:

```
python hrlcm/predict_interm_label.py --args_path '/scratch/lsong36/tanzania/results/unet_128_20bs_sbaug_tune/checkpoints/args.pkl' --checkpoint_file '/scratch/lsong36/tanzania/results/unet_128_20bs_sbaug_tune/checkpoints/final.pth' --year '2018' --fname_predict 'training/dl_catalog_ipredict_2018.csv' --data_dir '/scratch/lsong36/tanzania' --out_dir '/scratch/lsong36/tanzania/training/label' --stats_dir '/scratch/lsong36/tanzania/training/norm_stats' --num_workers 24 --batch_size 64 --gpu_devices '0,1' --label_format 'full'
```

2019:

```
python hrlcm/predict_interm_label.py --args_path '/scratch/lsong36/tanzania/results/unet_128_20bs_sbaug_tune/checkpoints/args.pkl' --checkpoint_file '/scratch/lsong36/tanzania/results/unet_128_20bs_sbaug_tune/checkpoints/final.pth' --year '2019' --fname_predict 'training/dl_catalog_ipredict_2019.csv' --data_dir '/scratch/lsong36/tanzania' --out_dir '/scratch/lsong36/tanzania/training_2019/label' --stats_dir '/scratch/lsong36/tanzania/training/norm_stats' --num_workers 24 --batch_size 64 --gpu_devices '0,1' --label_format 'intersect'
```

### Predict

No need to use intensive GPU resource because the prediction is made tile by tile. Use one A100 GPU with batch size 64, 35 cores, CPU RAM 100G:

```
python hrlcm/predict.py --args_path '/scratch/lsong36/tanzania/results/unet_128_20bs_sbaug_tune/checkpoints/args.pkl' --checkpoint_file '/scratch/lsong36/tanzania/results/unet_128_20bs_sbaug_tune/checkpoints/final.pth' --year '2019' --fname_predict 'training/dl_catalog_predict_2019.csv' --data_dir '/scratch/lsong36/tanzania' --out_dir '/scratch/lsong36/tanzania/prediction' --stats_dir '/scratch/lsong36/tanzania/training/norm_stats' --num_workers 35 --batch_size 64 --gpu_devices '0'
```

## Other useful commands

### Check disk space and clean trash

```bash
df -H
cd ~/.local/share/Trash/
rm -rf *
```
### Check the RAM usage in M

```bash
free -m
```

### Copy files from/to S3

To:

```
aws s3 cp --recursive $HOME/hrlcm/results/dl s3://activemapper/leisong/model

while true; do aws s3 cp --recursive $HOME/hrlcm/results/dl/unet_full_startup_80epochs s3://activemapper/leisong/model/unet_full_startup_80epochs; sleep 50m; done

aws s3 cp --recursive $HOME/hrlcm/results/prediction_zone1_125 s3://activemapper/leisong/prediction/
```

From:

```
aws s3 cp --recursive s3://activemapper/leisong/unet_full_12bs_4augs_120epochs/ $HOME/hrlcm/results/dl/unet_full_12bs_4augs_120epochs
```